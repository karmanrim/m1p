| Название | Год | Автор | Ссылка | Краткое содержание |
| -------- |---- | ----- | ------ | ------------------ |
| Generative adversarial nets | 2014 | Ian Goodfellow et al. | [Link](https://arxiv.org/abs/1406.2661) | Основополагающая работа о генеративных состязательных сетях (GAN). |
| Alias-free generative adversarial networks | 2021 | Tero Karras et al. | [Link](https://arxiv.org/abs/2106.12423) | Представлена новая архитектура GAN без артефактов сглаживания. |
| Wasserstein GAN | 2017 | Martin Arjovsky et al. | [Link](https://arxiv.org/abs/1701.07875) | Изучается использование расстояния Васерштейна для улучшения стабильности обучения GAN. |
| Improved training of Wasserstein GANs | 2017 | Ishaan Gulrajani et al. | [Link](https://arxiv.org/abs/1704.00028) | Представлены улучшенные методы обучения для WGAN. |
| A style-based generator architecture for generative adversarial networks | 2019 | Tero Karras et al. | [Link](https://arxiv.org/abs/1812.04948) | StyleGAN, улучшенная архитектура для генерации изображений высокого качества. |
| Large scale GAN training for high fidelity natural image synthesis | 2018 | Andrew Brock et al. | [Link](https://arxiv.org/abs/1809.11096) | Применение масштабных методов обучения GAN. |
| Bias and generalization in deep generative models | 2018 | Shengjia Zhao et al. | [Link](https://arxiv.org/abs/1809.06832) | Исследование смещения и обобщающей способности в глубоких генеративных моделях. |
| Catastrophic forgetting and mode collapse in GANs | 2020 | Hoang Thanh-Tung et al. | [Link](https://ieeexplore.ieee.org/document/9206829) | Исследуется проблема катастрофического забывания и коллапса мод в GAN. |
| Zero-shot text-to-image generation | 2021 | Aditya Ramesh et al. | [Link](https://arxiv.org/abs/2102.12092) | Разработка методов генерации изображений на основе текстовых описаний. |
| Understanding failures in out-of-distribution detection with deep generative models | 2021 | Lily Zhang et al. | [Link](https://arxiv.org/abs/2103.09955) | Анализ недостатков генеративных моделей при детекции выбросов. |
| Auto-encoding variational Bayes | 2013 | Diederik P. Kingma et al. | [Link](https://arxiv.org/abs/1312.6114) | Основополагающая работа о вариационных автоэнкодерах (VAE). |
| Stochastic backpropagation and approximate inference in deep generative models | 2014 | Danilo Jimenez Rezende et al. | [Link](https://arxiv.org/abs/1401.4082) | Применение стохастической обратной связи для обучения VAE. |
| Ffjord: Free-form continuous dynamics for scalable reversible generative models | 2018 | Will Grathwohl et al. | [Link](https://arxiv.org/abs/1810.01367) | Модели с обратимыми непрерывными динамическими процессами. |
| Residual flows for invertible generative modeling | 2019 | Ricky TQ Chen et al. | [Link](https://arxiv.org/abs/1906.02735) | Использование остаточных потоков для генеративного моделирования. |
| Vaebm: A symbiosis between variational autoencoders and energy-based models | 2020 | Zhisheng Xiao et al. | [Link](https://arxiv.org/abs/2010.00654) | Сочетание VAE и энергетических моделей. |
| Deep unsupervised learning using nonequilibrium thermodynamics | 2015 | Jascha Sohl-Dickstein et al. | [Link](https://arxiv.org/abs/1503.03585) | Исследование диффузионных моделей для обучения. |
| Denoising diffusion probabilistic models | 2020 | Jonathan Ho et al. | [Link](https://arxiv.org/abs/2006.11239) | Введение диффузионных моделей для восстановления изображений. |
| Generative modeling by estimating gradients of the data distribution | 2019 | Yang Song et al. | [Link](https://arxiv.org/abs/1907.05600) | Моделирование данных через оценку их градиентов. |
| Improved techniques for training score-based generative models | 2020 | Yang Song et al. | [Link](https://arxiv.org/abs/2006.09011) | Техники улучшения обучения score-based моделей. |
| Denoising diffusion implicit models | 2020 | Jiaming Song et al. | [Link](https://arxiv.org/abs/2010.02502) | Новая архитектура implicit диффузионных моделей. |
| Score-based generative modeling through stochastic differential equations | 2020 | Yang Song et al. | [Link](https://arxiv.org/abs/2011.13456) | Использование стохастических дифференциальных уравнений в генеративном моделировании. |
| Denoising diffusion restoration models | 2022 | Bahjat Kawar et al. | [Link](https://arxiv.org/abs/2201.11793) | Диффузионные модели для восстановления изображений. |
| Improved denoising diffusion probabilistic models | 2021 | Alex Nichol et al. | [Link](https://arxiv.org/abs/2102.09672) | Улучшенные диффузионные модели восстановления. |
| Diffusion models beat GANs on image synthesis | 2021 | Prafulla Dhariwal et al. | [Link](https://arxiv.org/abs/2105.05233) | Сравнение диффузионных моделей и GAN для синтеза изображений. |
| Variational diffusion models | 2021 | Diederik P. Kingma et al. | [Link](https://arxiv.org/abs/2107.00630) | Вариационные методы для диффузионных моделей. |
| Taylor Sampling Scheme for Denoising Diffusion Probabilistic Models | 2021 | Hideyuki Tachibana et al. | [Link](https://arxiv.org/abs/2112.13339) | Новый подход для ускорения выборки в диффузионных моделях. |
| Pseudo numerical methods for diffusion models on manifolds | 2022 | Luping Liu et al. | [Link](https://arxiv.org/abs/2202.09778) | Псевдо-численные методы для работы с диффузионными моделями. |
| Tackling the Generative Learning Trilemma with Denoising Diffusion GANs | 2021 | Zhisheng Xiao et al. | [Link](https://arxiv.org/abs/2112.07804) | Совмещение диффузионных моделей и GAN. |
| Progressive distillation for fast sampling of diffusion models | 2022 | Tim Salimans et al. | [Link](https://arxiv.org/abs/2202.00512) | Прогрессивная дистилляция для ускорения генерации. |
| Score-based generative modeling in latent space | 2021 | Arash Vahdat et al. | [Link](https://arxiv.org/abs/2110.07579) | Использование латентного пространства в score-based моделях. |
| Diffusion Normalizing Flow | 2021 | Qinsheng Zhang et al. | [Link](https://arxiv.org/abs/2110.07579) | Применение нормализующих потоков к диффузионным моделям. |
| Image super-resolution via iterative refinement | 2021 | Chitwan Saharia et al. | [Link](https://arxiv.org/abs/2104.07636) | Метод повышения разрешения изображений с использованием итеративного восстановления. |
| Grad-TTS: A diffusion probabilistic model for text-to-speech | 2021 | Vadim Popov et al. | [Link](https://arxiv.org/abs/2104.08665) | Диффузионные модели для преобразования текста в речь. |
| DiffGAN-TTS: High-Fidelity and Efficient Text-to-Speech with Denoising Diffusion GANs | 2022 | Songxiang Liu et al. | [Link](https://arxiv.org/abs/2201.11972) | Использование GAN и диффузионных моделей для преобразования текста в речь. |
| Diffusion probabilistic models for 3D point cloud generation | 2021 | Shitong Luo et al. | [Link](https://arxiv.org/abs/2103.16568) | Генерация 3D-облаков точек с помощью диффузионных моделей. |
| 3D shape generation and completion through point-voxel diffusion | 2021 | Linqi Zhou et al. | [Link](https://arxiv.org/abs/2106.13407) | Генерация и завершение 3D-форм через диффузионные модели. |
| Structured denoising diffusion models in discrete state-spaces | 2021 | Jacob Austin et al. | [Link](https://arxiv.org/abs/2107.03006) | Модели диффузионного восстановления в дискретных пространствах. |

