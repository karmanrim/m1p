
\documentclass[12pt,a4paper]{article}

\usepackage{authblk}
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[russian]{babel}
\usepackage{amsmath,amsfonts,amssymb,graphicx,hyperref}

\usepackage{arxiv}

\usepackage[utf8]{inputenc}
\usepackage[english, russian]{babel}
\usepackage[T1]{fontenc}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{lipsum}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{doi}


\title{Исследование возможности одновременного обучения диффузионной модели и текстового автокодировщика}
\author {
    Ким Роман Германович\textsuperscript{\rm 1, 2}\\
    Научный консультант: Мещанинов Вячеслав Павлович\textsuperscript{\rm 1} \\
    Научный руководитель: Темирчев Павел Георгиевич\textsuperscript{\rm 2}
   
}


\affil {
    % Affiliations
    \textsuperscript{\rm 1}Национальный исследовательский университет «Высшая школа экономики»\\
    \textsuperscript{\rm 2}Московский государственный университет имени М. В. Ломоносова\\
vmeshchaninov@hse.ru, rkim@hse.ru
}

\begin{document}

\maketitle

\begin{abstract}
Генеративные модели занимают важное место в современном машинном обучении и обработке сигналов, применяясь для синтеза изображений, аудио, 3D-объектов и текста. С течением времени подходы к генерации данных стали более разнообразными и мощными: от Генеративно-состязательных сетей (GAN) \cite{goodfellow2014generative} до Вариационных Автоэнкодеров (VAE) \cite{kingma2013auto,rezende2014stochastic}, поточных моделей \cite{grathwohl2018ffjord,chen2019residual} и энергетических моделей \cite{xiao2020vaebm}, а в последние годы – диффузионных моделей \cite{sohl2015deep,ho2020denoising}. В частности, диффузионные модели продемонстрировали превосходство над классическими методами генерации изображений, а впоследствии стали активно развиваться в задачах генерации текстов \cite{austin2021structured,diffusionlm,diffuseq,difformer,planner,dinoiser}. Однако переход к дискретным пространствам, характерным для текстовых данных, ставит новые вызовы, которые стимулируют поиск интегральных решений, совмещающих автокодировщики и диффузионные модели для упрощения задачи восстановления структуры и смысла текста.

Данная статья нацелена исследовать возможность одновременного обучения диффузионной модели и автокодировщика. Также будет предложены две конфигурации для одновременного обучения.
\end{abstract}

\section{Введение}

Современные генеративные модели охватывают широкий спектр методов:
\begin{itemize}
    \item \textbf{GAN (Generative Adversarial Networks):} Предложенные в \cite{goodfellow2014generative}, GAN получили широкую популярность благодаря способности генерировать реалистичные изображения. Последующие работы улучшили стабильность обучения (Wasserstein GAN \cite{arjovsky2017wasserstein,gulrajani2017improved}), качество (StyleGAN \cite{karras2019style,karras2021alias}) и масштабируемость \cite{brock2018large}. Тем не менее, GAN страдают от проблем смещения, катастрофического забывания и \emph{mode collapse} \cite{zhao2018bias,thanh2020catastrophic}.
    \item \textbf{VAE (Variational Autoencoders):} Модели на основе вариационных автоэнкодеров \cite{kingma2013auto,rezende2014stochastic} вводят вероятностный подход к обучению латентного представления. Однако качество сгенерированных ими изображений часто уступает GAN.
    \item \textbf{Поточные модели (Flow-based models):} Обращаемые преобразования плотности \cite{grathwohl2018ffjord,chen2019residual} позволяют напрямую моделировать распределение данных, но требуют больших вычислительных ресурсов.
    \item \textbf{Энергетические модели (EBM):} Подходы \cite{xiao2020vaebm} предлагают вероятностную интерпретацию через энергетический ландшафт, но обучение EBM нетривиально.
\end{itemize}

В последние годы особое внимание уделяется диффузионным моделям \cite{ho2020denoising,sohl2015deep,song2019generative,song2020improved,song2020denoising,song2020score,nichol2021improved,dhariwal2021diffusion,kingma2021variational}, продемонстрировавшим превосходство в широком спектре задач: от сверхразрешения изображений \cite{saharia2021image} и синтеза аудио \cite{popov2021grad,liu2022diffgan} до генерации 3D-объектов \cite{luo2021diffusion,zhou20213d}, но при работе с текстами у диффузионных моделей происходят проблемы, так как они были придуманы для непрерывных данных (изображений, звука), а пространств слов - дискретное, вследствие чего приходится, либо переводить дискретное пространство текстов в непрерывное, либо адаптировать работу диффузионной модели на дискретные пространства.
В данной статье будет рассматриваться непрерывная диффузионная модель, работающая с непрерывным пространством энкодингов.

\section{Формальное описание задачи генерации текста}

\subsection{Классические методы генерации текста}

Классическая задача генерации текста с помощью нейронных сетей формулируется в терминах максимизации правдоподобия текстов из обучающей выборки.
\begin{align}
\prod_{x\in X} p_\theta(x) = \prod_{x\in X} p_\theta(x_1, \dots, x_{n_x}) = \prod_{x\in X} \bigg(p_\theta(x_1) \prod_{i=2}^{n_x} p_\theta(x_i \mid x_1, \dots, x_{i-1})\bigg) \to \max_\theta,
\end{align}

где $x$ -- текст из обучающей выборки $X$, а $n_x$ -- число слов в этом тексте. Для того, чтобы убрать безусловную вероятность $p_\theta(x_1)$ из функционала, в начало текста добавляют фиксированный символ начала последовательности $x_0 = \text{``bos''}$. Тогда все вероятности становятся условными.
\begin{align}
\prod_{x\in X} \bigg(\prod_{i=1}^{n_x} p_\theta(x_i \mid x_1, \dots, x_{i-1})\bigg) \to \max_\theta
\end{align}

Функционал ошибки, минимизируемый в процессе оптимизации получается из данного правдоподобия с помощью наложения на него логарифма и домножения на $-1$.
\begin{align}
-\sum_{x\in X} \bigg(\sum_{i=1}^{n_x} \ln p_\theta(x_i \mid x_1, \dots, x_{i-1})\bigg) \to \min_\theta
\end{align}

В соответствии с полученным функционалом ошибки обучается нейронная сеть, которая принимает на вход последовательность слов и возвращает условное распределение на слова, которые могут быть сгенерированы в качестве продолжения. Процесс генерации текста в таких моделях является авторегрессионным. То есть слова генерируются по-очереди.

\subsection{Диффузионные методы генерации текста}

У авторегрессионной генерации есть три основных недостатка. Для того, чтобы сгенерировать текст длины $n$, необходимо вызвать модель $n$ раз. Из-за этого генерация длинных текстов работает относительно долго.

Во-вторых, авторегрессионным моделям свойственна генерация повторяющихся фраз. Такое поведение возникает из-за оптимизируемого функционала. В ситуации, когда текст содержит повторы, вероятность появления дополнительно повтора возрастает и, вследствии этого, модель с каждым новым словом начинает чаще генерировать повторяющиеся фразы \cite{theoretical_repetitions}. Для исправления этого недостатка приходится подбирать параметры для выбора токенов из предсказанного распределения, что усложняет настройку модели. 


И наконец, авторегрессионные модели не могут исправлять свои ошибки. Например, при генерации стихов из-за того, что модель не смотрит в будущее, она может сгенерировать слово, к которому нет подходящей рифмы. В этом случае весь следующий текст будет испорчен.


Диффузионные модели решают все эти проблемы. Они итеративно генерируют объекты из шума, приближая вероятность исходных данных. При применении к тексту такой метод позволяет генерировать все слова одновременно, так как модель воспринимает текст как единый объект. При этом для генерации требуется фиксированное число итераций (около 100), меньшее, чем необходимо для генерации длинного текста авторегрессионно.

Обучение диффузионной модели происходит с помощью стохастического градиентного спуска, в котором считается градиент функционала ошибки по параметрам модели. Так как текст имеет дискретную природу, если модель будет предсказывать его напрямую, то градиент посчитать будет невозможно. По этой причине, диффузионные модели обычно работают в пространстве непрерывных векторных представлений слов \cite{li2022diffusion, chen2022analog}. При обучении  перед зашумлением каждое слово отображается в соответствующий вектор, а при генерации после последней итерации каждый сгенерированный вектор слова отображается обратно в текст.


\subsection{Непрерывная диффузионная модель}
Непрерывные диффузионные модели повторяют идею диффузионных моделей, применяемых для изображений и аудио. В них объект зашумляется с помощью вливания в него гауссовского шума.
\begin{align}
    q(x_t | x_s) = \mathcal{N}(x_t; \alpha_{t|s} x_{s}, \sigma_{t|s}^2 I)
\end{align}

Для текста в числовом формате чаще всего используются векторные представления токенов фиксированной длины \cite{diffusionlm, diffuseq, yuan2022seqdiffseq, lin2023genie, planner, dinoiser, difformer}. Однако иногда модель обучают на симплексе \cite{han2023ssdlmsemiautoregressivesimplexbaseddiffusion, mahabadi2024tesstexttotextselfconditionedsimplex}, представляя каждый токен в виде вектора ${+k, -k}^{|V|}$, где $+k$ стоит на месте индекса токена, а на всех остальных позициях стоит $-k$.

\section{Постановка задачи и варианты решения}

В данной статье рассматривается модель состоящая из автокодировщика и диффузионной модели. В настоящее время в большинстве работ по диффузионным моделям обучение автокодировщика и диффузионной модели происходит раздельно, но одновременное обучение модели упрощает общий конвейер обучение и потенциально снижает количество источников ошибок во время обучения.

Предлагаемые варианты решения:

\subsection{Конфигурация № 1}
\begin{align} 
& x_0 = \text{Enc}(w) \\
& x_0 = \text{Normalize}(x_0) \\
& t \sim U[0, 1], \varepsilon \sim \mathcal{N}(0, I)\\ 
& x_t = \alpha_t x_0 + \sigma_t \varepsilon, \\
& \hat{x}_0 = \text{Dif}(x_t, 0, t)] \\
& \text{if }\zeta < \frac{1}{2} \text{ then } \\
& \qquad \hat{x}_0 = model(x_t, SG[\hat{x}_0], t) \\
& \hat{w} = Dec(\hat{x}_0)\\
& \mathcal{L}_{dif} = ||x_0 - \hat{x}_0||^2 \rightarrow \min_{dif} \\
& \mathcal{L}_{ae} = \text{CE}(w, \hat{w}) \rightarrow \min_{enc, dec}
\end{align} 
В этой конфигурации используется две функции ошибки: $L_{ae}$ -- функция ошибки кодировщика и декодировщика, $L_{dif}$ -- функция ошибки диффузионной модели.
Важно заметить, что $L_{ae}$ не оптимизируется по параметрам диффузии, так как обратное приводит к коллапсу диффузионной модели. Также важно отметить, что автокодировщик и диффузионная модель связаны, так как вход декодировщика -- это выход диффузионной модели.

\subsection{Конфигурация № 2}
\begin{align} 
& x_0 = \text{Enc}(w) \\
& x_0 = \text{Normalize}(x_0) \\\\
& t \sim U[0, 1], \varepsilon \sim \mathcal{N}(0, I)\\ 
& x_t = \alpha_t x_0 + \sigma_t \varepsilon, \\\\
& \hat{x}_0 = \text{Dif}(x_t, 0, t)] \\
& \text{if }\zeta < \frac{1}{2} \text{ then } \\
& \qquad \hat{x}_0 = model(x_t, SG[\hat{x}_0], t) \\\\
& \hat{w} = Dec(\hat{x}_0)\\\\
& \mathcal{L}_{dif} = ||x_0 - \hat{x}_0||^2 \rightarrow \min_{dif} \\
& \mathcal{L}_{сe} = \text{CE}(w, \hat{w}) + ||x_0 - SG[\hat{x}_0]||^2 \rightarrow \min_{enc, dec}
\end{align} 
Вторая конфигурация похожа на первую, но в функции потерь автокодировщика добавляется слагаемое для большей связи диффузионной модели и автокодировщика.
Важно отметить, что стохастический градиент убирать из $L_{сe}$ нельзя, так как кодировщик будет стремиться сделать все токены константными или уменьшить их норму до нуля.

\section{Эксперименты}

Для экспериментов использовались датасеты (Wikipedia \cite{dodge2021documenting}, Rocstories, XSUM), различные метрики качества (PPL, MAUVE, Rouge, BERTScore, Meteor). За архитектуру диффузионной модели взята архитектура LLaMa \cite{touvron2023llamaopenefficientfoundation}: 12 голов, 12 слоев. Размер рассматриваемой модели $\sim100$ млн параметров

В секциях !!! эксперименты будут проводится с моделью в конфигурации 1, для задачи безусловной генерации, длина генерации 8 токенов

\subsection{Влияние размера обучающих данных на качество модели}
Обучим модель в первой конфигурации на задаче безусловной генерации текста на Rocstories (размер набора данных $\sim 119000$) и на Wikipedia (размер набора данных $\sim 2$млн.) Результаты представлины на Рис. \ref{fig:1}
\begin{figure}[h!]
\centering
\includegraphics[width=0.6\linewidth]{images_roma/var1exp2img1.pdf}
\caption{Функция потерь диффузионной модели на валидационной выборке при одновременном обучении. (фиолетовая линия -- Rocsories, оранжевая -- Wikipedia)}
\label{fig:1}
\end{figure}

По Рис. \ref{fig:1} можно сделать вывод, что размера Rocstories недостаточно для корректного обучения модели, поэтому последующие эксперименты будут проводиться на наборе данных Wikipedia.
\subsection{Важность и подбор нормализации}
Как можно заметить в каждой конфигурации участвует нормализаци данных, в данной секции будет приведено теоретическое доказательство важности нормализации и подбор лучшего вида нормализации.
\subsubsection{Обоснование}
Рассмотрим модель без нормализации.

Получаем векторные представления слов $x_0 = \text{Enc}(w)$, пусть $||x_0|| \rightarrow \infty$, тогда $x_t = \alpha_t x_0 + \sigma_t \varepsilon \approx \alpha_t x_0$, $\hat{x}_0 = \text{Dif}(\alpha_t x_0, t) \approx x_0$, потому что диффузионная модель учится предсказывать $x_0$, следовательно  $\hat{w} = Dec(x_0)$.

Из этого следует, что кодировщику выгодно увеличивать норму $x_0$, чтобы делать задачу декодировщика проще.
\subsubsection{Подбор типа нормализации}
Для начала введем рассматриваемые типы нормализации:
\begin{enumerate}
    \item Нормализация на сферу (SphereNorm)
    \item Нормализация по куску данных (BatchNorm)
    \item Нормализация по слою (LayerNorm)
    \item Нормализация по всему набору данных (DataNorm)
\end{enumerate}

Первые три варианта нормализации достаточно распространены и не требуют дополнительного объяснения, в свою очередь DataNorm может быть реализовано по-разному, а точнее может быть разная реализация сглаживания среднего отклонения, поэтому ниже будет представлен вариант сглаживания.

Рассмотрим, как можно сглаживать среднее отклонение:
\begin{align} 
& x_n = \frac{1}{BS} \sum_{B, S} e_i \\ 
& y_n = \frac{1}{BS} \sum_{B, S} e_i^2\\\\
& \mu_n = (1 - \alpha) \mu_{n-1} + \alpha x_n = \mu_{n-1} + \alpha (x_n - \mu_{n-1}) \\
& q_n = q_{n-1} + \alpha * (y_n - q_{n-1}) \\\\
& \sigma_n = \sqrt{q_n - \mu_n^2}
\end{align} 
Обучим модель с разными коэффициентами сглаживания для нормализации.

\begin{table}[h!]
\caption{Результаты модели обученной с DataNorm}
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
$\alpha$ & PPL ↓ & Mauve ↑ & Div ↑ & Memorization ↓ \\ \hline
$0.99$ & $293.9$ & $0.921$ & $0.645$ & $0.362$ \\ \hline
$0.01$ & $294.3$ & $0.943$ & $0.666$ & $0.354$ \\ \hline
\end{tabular}
\label{table:4.4}
\end{table}
Из таблицы \ref{table:4.4}, можно сделать вывод, что модель с коэффициентом сглаживания 0.01 лучше по метрикам Mauve, Div, Memorization, при этом по метрике перплексия разница незначительная (0.4), в следствии чего, модель с коэффициентом сглаживания 0.01 выбрана лучшей.

Теперь сравним виды нормализации:
\begin{table}[h!]
\caption{Результаты модели с разными нормалиациями}
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
Тип нормализации & PPL ↓ & Mauve ↑ & Div ↑ & Mem ↓ \\ \hline
Sphere Norm & $319.5$ & $0.932$ & $0.672$ & $0.324$ \\ \hline
Layer Norm & $326.0$ & $0.904$ & $0.674$ & $0.322$ \\ \hline
Data Norm & $294.4$ & $0.943$ & $0.666$ & $0.354$ \\ \hline
Batch Norm & $344.1$ & $0.934$ & $0.705$ & $0.319$ \\ \hline
\end{tabular}
\label{tab:5}
\end{table}
По результатам из таблицы \ref{tab:5} BatchNorm показал себя хуже, чем остальные варианты нормализации. При этом DataNorm лучший вариант нормализации, поэтому в будущем будем использовать именно его. 

\subsection{Сравнение конфигураций с существующими диффузионными моделями}

В данной секции будет произведено сравнение качества реализованных конфигураций и существующих диффузионных моделей на задачах суммаризации и безусловной генерации. Для сравнения взяты модели такого же размера, а именно LD4LG \cite{lovelace2023latentdiffusionlanguagegeneration} и TEncDM \cite{shabalin2024tencdmunderstandingpropertiesdiffusion}

\subsubsection{Безусловная задача}
Сравнение двух подходов с существующими моделями на задаче безусловной генерации на наборе данных Wikipedia, длина генерации 128 токенов, нормализация DataNorm.
\begin{table}[h!]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
& PPL ↓ & Mauve ↑ & Div ↑ & Mem ↓ \\ \hline
(1) & $71.9$ & $0.908$ & $0.447$ & $0.355$ \\ \hline
(2) & $71.6$ & $0.914$ & $0.527$ & $0.304$ \\ \hline
LD4LG & $70.3$ & $0.912$ & $0.533$ & $0.295$ \\ \hline
TEncDM & $68.9$ & $0.921$ & $0.540$ & $0.286$ \\ \hline
\end{tabular}
\caption{Результаты запуска конфигураций на безусловной задаче}
\label{tab:wiki}
\end{table}

\subsubsection{Запуск на задаче суммаризации}
Для сравнения выбран набор данных XSUM, длина генерации 40 токенов.
В таблице \ref{tab:2} представлены результаты сравнения на задаче суммаризации.

\begin{table}[h!]
\centering
\begin{tabular}{|c|c|c|c|c||}
\hline
& Rouge-1 ↑ & Rouge-2 ↑ & Rouge-L ↑ & BERT Score ↑  \\ \hline
(1) &  $0.227$ & $0.040$ & $0.175$ & $0.599$ \\ \hline
(2) &  $0.237$ & $0.052$ & $0.182$ & $0.642$  \\ \hline
LD4LG & $0.381$ & $0.159$ & $0.312$ & $0.748$ \\ \hline
TEncDM &  $0.337$ & $0.119$ & $0.271$ & $0.698$ \\ \hline
\end{tabular}
\caption{Результаты сравнения на задаче суммаризации}
\label{tab:2}
\end{table}
\subsubsection{Анализ результатов}
Как видно из таблицы \ref{tab:wiki}, модель обученная во второй конфигурация по всем метрикам обходит модель обученную в первую конфигурации, это может быть связано с тем, что у второй конфигурации связь между диффузионной моделью и автокодировщиком сильнее, это может быть важно для задачи безусловной генерации. Также хочется отметить, что хоть обе конфигурации проигрывают существующим моделям, но значение метрик отличается всего на 5-10 процентов.

На задаче суммаризации таблица \ref{tab:2} ситуация такая же, снова конфигурация 2 показывает себя лучше, чем конфигурация 1. Также можно увидеть, что на этой задаче существующие диффузионные модели лучше в 1,5 - 2 раза по всем метрикам. 

\section{Будущая работа}

Как видно из таблиц \ref{tab:wiki}, \ref{tab:2} предоставленные конфигурации проигрывают по метрикам существующим моделям без применения одновременного обучение, это озночает, что данные конфигурации еще требуют улучшения, данную задачу улучшения мы оставляем на будущее, так как в данной работе хочется показать возможность использования технологии одновременного обучения для диффузионных моделей.

\section{Выводы}

В данной работе было рассмотрено два подхода к одновременному обучению диффузионной модели и текстового автокодировщика. Первый подход основывался на обучении автокодировщика независимо от диффузии, хотя и с учётом её выходов. Во втором подходе была усилена связь между автокодировщиком и диффузионной моделью, добавив слагаемое в функцию потерь автокодировщика, учитывающее выход диффузии.

Проведённые эксперименты показали, что:
\begin{enumerate}
    \item Непосредственное совместное обучение автокодировщика и диффузионной модели возможно и упрощает общий конвейер, так как не требуется отдельного этапа предварительного обучения автокодировщика.
    \item Выбор нормализации и объёма обучающих данных существенно влияет на качество. На малых наборах данных модель склонна к переобучению и деградации качества. Расширение объёма обучающей выборки (например, с Rocstories на Wikipedia) положительно сказывается на результатах.
    \item Использование DataNorm для нормализации выходов автокодировщика дает лучшие результаты по сравнению с другими рассмотренными способами нормализации (BatchNorm, LayerNorm, SphereNorm).
    \item Вторая конфигурация, усиливающая связь между автокодировщиком и диффузионной моделью, в ряде случаев показывает более высокое качество на задачах безусловной генерации текста по сравнению с первой конфигурацией.
    \item Несмотря на улучшения по сравнению с первой конфигурацией, предложенные подходы пока уступают по качеству существующим методам, в которых автокодировщик и диффузионная модель обучаются раздельно.
\end{enumerate}

Таким образом, совместное обучение автокодировщика и диффузионной модели является перспективным направлением, позволяющим потенциално упростить и унифицировать процесс обучения. Однако для достижения конкурентного качества требуется дополнительная проработка архитектурных решений, функций потерь и методов нормализации, а также экспериментирование с ещё более крупными наборами данных и новыми методами регуляции.
\include{biblio}

\end{document}
